{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pretty prints\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating directory for json configs\n",
    "import os\n",
    "\n",
    "if not os.path.isdir(\"gobot\"):\n",
    "    os.mkdir(\"gobot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import deeppavlov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE**: \"go_bot\" model trains faster on a CPU, so let's ignore existing GPUs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda visible devices = ''\r\n"
     ]
    }
   ],
   "source": [
    "!export CUDA_VISIBLE_DEVICES=\"\"\n",
    "!echo \"cuda visible devices = '\"$CUDA_VISIBLE_DEVICES\"'\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hybrid goal-oriented bot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dialog bots are categorized into two types:\n",
    "\n",
    "1. **goal-oriented models **\n",
    "\n",
    "    (those who have to achieve some kind of a goal in the end of conversation: \n",
    "     - restaurant and flight booking,\n",
    "     - customer support service,\n",
    "     - etc.);\n",
    " \n",
    "2. **chit-chat models **\n",
    "\n",
    "   (those who chat just for fun, the longer bot speaks with you the better, example:\n",
    "    - \"replica\" mobile application).\n",
    "\n",
    "We will only dive into goal-oriented task specification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![go bot architecture 00](img/bot_architecture00.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classical dialog system consists of:\n",
    "\n",
    "1. **Natural Language Understanding component (NLU)**\n",
    "\n",
    " that is intended to \"understand\" human and represent it's \"understanding\" in a machine readable format. \n",
    "\n",
    " It takes an utterance text as input and converts to a dialog \"frame\".\n",
    "\n",
    " \"Frame\" may consist of:\n",
    "   - domain value (domain is some kind of \"a type of dialogs\");\n",
    "   - intent value (intent of current human utterance: \"welcome_message\", \"asking_weather\", etc.);\n",
    "   - entity slots (entities are mentioned by human \"location\", \"time\", etc.).\n",
    "\n",
    "2. **Dialogue Manager component (DM)**\n",
    "\n",
    " that is intended to decide what to respond. \n",
    "    \n",
    " It takes a filled by NLU frame and outputs action (it isn't a final text, it is a label). \n",
    "    \n",
    " For example, there may be actions: \"say_welcome\", \"say_goodbye\", \"ask_location\", \"give_weather\", etc.\n",
    "\n",
    "3. **Natural Language Generation component(NLG)**\n",
    "\n",
    " that is intended to convert action to an actual text response representation.\n",
    " \n",
    " For example, \"say_goodbye\" -> \"You are welcome!\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLU "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![go bot architecture 01](img/bot_architecture01.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider a dialog system with NLU component that consists of a single Named Entity Recognition \n",
    "    component (or NER)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the previous tutorials introduced deeppavlov NER model and showed how to use it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DM & NLG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tutorial is focused on how to implement\n",
    " - Dialogue Manager and\n",
    " - Natural Language Generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the chatbot on a [Dialog State Tracking Chellenge 2](http://camdial.org/~mh521/dstc/) data.\n",
    "\n",
    "Let's download it first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-07-09 13:43:12.972 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 197: [downloading data from http://files.deeppavlov.ai/datasets/dstc2_v2.tar.gz to tmp/my_download_of_dstc2]\n",
      "2018-07-09 13:43:12.976 INFO in 'requests.packages.urllib3.connectionpool'['connectionpool'] at line 203: Starting new HTTP connection (1): lnsigo.mipt.ru\n",
      "2018-07-09 13:43:13.554 DEBUG in 'requests.packages.urllib3.connectionpool'['connectionpool'] at line 383: \"GET /export/datasets/dstc2_v2.tar.gz HTTP/1.1\" 200 506300\n",
      "2018-07-09 13:43:13.557 INFO in 'deeppavlov.core.data.utils'['utils'] at line 65: Downloading from http://files.deeppavlov.ai/datasets/dstc2_v2.tar.gz to /home/vimary/ipavlov/Pilot/examples/tutorials/tmp/my_download_of_dstc2/dstc2_v2.tar.gz\n",
      "100%|██████████| 506k/506k [00:00<00:00, 1.62MB/s]\n",
      "2018-07-09 13:43:13.875 INFO in 'deeppavlov.core.data.utils'['utils'] at line 149: Extracting tmp/my_download_of_dstc2/dstc2_v2.tar.gz archive into tmp/my_download_of_dstc2\n",
      "2018-07-09 13:43:13.925 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 214: [loading dialogs from tmp/my_download_of_dstc2/dstc2-trn.jsonlist]\n",
      "2018-07-09 13:43:14.54 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 214: [loading dialogs from tmp/my_download_of_dstc2/dstc2-val.jsonlist]\n",
      "2018-07-09 13:43:14.154 INFO in 'deeppavlov.dataset_readers.dstc2_reader'['dstc2_reader'] at line 214: [loading dialogs from tmp/my_download_of_dstc2/dstc2-tst.jsonlist]\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.dataset_readers.dstc2_reader import DSTC2Version2DatasetReader\n",
    "\n",
    "data = DSTC2Version2DatasetReader().read(data_path=\"tmp/my_download_of_dstc2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`DSTC2Version2DatasetReader` downloaded the needed data and saved to disk.\n",
    "\n",
    "`DialogDatasetIterator` took the data as input and transformed it to batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.dataset_iterators.dialog_iterator import DialogDatasetIterator\n",
    "\n",
    "batches_generator = DialogDatasetIterator(data, seed=1443, shuffle=True)\\\n",
    "                                         .gen_batches(batch_size=4, data_type='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-------------\n",
    "-------------\n",
    "   Let's take a closer look at a batch content:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = batches_generator.__next__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each batch is a tuple of two elements:\n",
    "  - list of x's and\n",
    "  - list of y's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch, y_batch = batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`x_batch` (and `y_batch`) consists of 4 samples. This is because `batch_size` was 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One sample is a dialog. This is how one turn from a dialog looks like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----0th turn----\n",
      "(       {'intents': [], 'prev_resp_act': None, 'text': ''},\n",
      "        {       'act': 'welcomemsg',\n",
      "                'text': 'Hello, welcome to the Cambridge restaurant system. '\n",
      "                        'You can ask for restaurants by area, price range or '\n",
      "                        'food type. How may I help you?'})\n"
     ]
    }
   ],
   "source": [
    "dialog_id = 0\n",
    "dialog = [(x, y) for x, y in zip(x_batch[dialog_id], y_batch[dialog_id])]\n",
    "\n",
    "turn_id = 0\n",
    "print(\"----{}th turn----\".format(turn_id)) \n",
    "pprint(dialog[turn_id], indent=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how the whole dialog looks (printing `'text'` parts of `x_batch` and `y_batch`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ":: \n",
      ">> Hello, welcome to the Cambridge restaurant system. You can ask for restaurants by area, price range or food type. How may I help you? \n",
      "\n",
      ":: traditional\n",
      ">> api_call area=\"dontcare\" food=\"traditional\" pricerange=\"dontcare\" \n",
      "\n",
      ":: traditional\n",
      ">> I am sorry but there is no traditional restaurant that matches your request. \n",
      "\n",
      ":: italian food\n",
      ">> What part of town do you have in mind? \n",
      "\n",
      ":: south\n",
      ">> api_call area=\"south\" food=\"italian\" pricerange=\"dontcare\" \n",
      "\n",
      ":: south\n",
      ">> Pizza hut cherry hinton is a nice place in the south of town serving tasty italian food. \n",
      "\n",
      ":: phone number\n",
      ">> The phone number of pizza hut cherry hinton is 01223 323737. \n",
      "\n",
      ":: post code\n",
      ">> The post code of pizza hut cherry hinton is C.B 1, 7 D.Y. \n",
      "\n",
      ":: thank you good bye\n",
      ">> You are welcome! \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for turn in dialog:\n",
    "    x, y = turn\n",
    "    print('::', x['text']) \n",
    "    print('>>', y['text'], '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HowTo: DeepPavlov configs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DeepPavlov uses json configs as a tool to configure data pipelines.\n",
    "\n",
    "Config has the following sections:\n",
    "     \n",
    " - **dataset_reader**\n",
    "   - configuration of dataset reader component (is responsible for data download and saving to disk);\n",
    "  \n",
    " - **dataset_iterator**\n",
    "   - configuration of dataset iterator component (is responsible for making batches (sequences) of data that will be further fed to pipe components);\n",
    "  \n",
    " - **metadata**\n",
    "   - extra info (urls for data download and telegram configuration);\n",
    "\n",
    " - **train**\n",
    "   - training process configuration (size of batches, number of training epochs, etc.);\n",
    "   \n",
    " - **chainer**\n",
    "   - specifies data flow (which components are run and in what order);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's construct a simple config that builds a dictionary of input sample tokens."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_config = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **dataset_reader** -- configuration of dataset reader component (that is responsible for data download and saving to disk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstc2_reader_comp_config = {\n",
    "    'name': 'dstc2_v2_reader',\n",
    "    'data_path': 'dstc2_v2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_config['dataset_reader'] = dstc2_reader_comp_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **dataset_iterator** -- configuration of dataset iterator component (that is responsible for making batches (sequences) of data that will be further fed to pipe components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dialog_iterator_comp_config = {\n",
    "    'name': 'dialog_iterator'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_config['dataset_iterator'] = dialog_iterator_comp_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **metadata** -- some extra info\n",
    "     - **metadata.download** -- a list of data which should be downloaded in order for config to work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstc2_download_config = {\n",
    "    'url': 'http://files.deeppavlov.ai/datasets/dstc2_v2.tar.gz',\n",
    "    'subdir': 'dstc2_v2'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_config['metadata'] = {}\n",
    "vocab_config['metadata']['download'] = [\n",
    "    dstc2_download_config\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **train** -- training process configuration\n",
    "     \n",
    "We don't need to train anything now, just build (fit on whole dataset once) a dictionary, so \"train\" section is empty."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_config['train'] = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - **chainer** specifies data flow:\n",
    " \n",
    "     - **chainer.in** -- is a list of input sample names (one data sample might consist of several variables);\n",
    "     - **chainer.in_y** -- is a list of input label names (each sample might have labels of different kind);\n",
    "     - **chainer.out** -- is a list of output prediction names (usually has the same length as \"chainer.in_y\");\n",
    "     \n",
    "X is only an utterance here.\n",
    "\n",
    "Y is empty (we don't need to train the dictionary like neural networks)\n",
    "\n",
    "There is no prediction for the config, nothing to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_config['chainer'] = {}\n",
    "vocab_config['chainer']['in'] = ['utterance']\n",
    "vocab_config['chainer']['in_y'] = []\n",
    "vocab_config['chainer']['out'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **chainer**\n",
    "     - **chainer.pipe** -- is a list of consequently run components. This is the place where you specify in which order and what kind of data will be fed to components. \n",
    "     \n",
    "Our pipe consists of one component -- \"default_vocab\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### HowTo: Component config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Component configs are always just a part of a global model config (described above).\n",
    "\n",
    "Config for any component contains the following **_required_** parameters:\n",
    " - **name** -- registered name of a component (it is a link to python component implementation)\n",
    " - **save_path** -- path to save the component (sometimes is not needed, for example, for tokenizers)\n",
    " - **load_path** -- path to load the component (sometimes is not needed, for examples, for tokenizers)\n",
    "\n",
    "and the following **_optional_** parameters:\n",
    " - **id** -- reference name for the component\n",
    " - **ref** -- \"id\" of a component that was previously initialized. It can be used instead of \"name\".\n",
    " - **fit\\_on** -- a list of data fields to fit on (it calls \\_\\_fit\\_\\_ method of the component)\n",
    " - **in** -- a list of data fields that are inputs during inference (prediction)\n",
    " - **out** -- a list of data fields that are outputs during inference (prediction)\n",
    " \n",
    " \n",
    "\"default_vocab\" component also has it's on unique parameters:\n",
    " - level -- on which level to operate ('token' level and 'char' (character) level are available)\n",
    " - tokenizer -- if input is a string, then it will be tokenized by the tokenizer, _optional parameter_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_comp_config = {\n",
    "    'name': 'default_vocab',\n",
    "    'save_path': 'vocabs/token.dict',\n",
    "    'load_path': 'vocabs/token.dict',\n",
    "    'fit_on': ['utterance'],\n",
    "    'level': 'token',\n",
    "    'tokenizer': {'name': 'split_tokenizer'},\n",
    "    'main': True\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_config['chainer']['pipe'] = [\n",
    "    vocab_comp_config\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(vocab_config, open(\"gobot/vocab_config.json\", 'wt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To download \"dstc2_v2\" dataset use `deeppavlov.deep_download` script (you have to do it only once):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.download import deep_download # it is called \"deep\" in honor of \"Deep Pavlov\"\n",
    "\n",
    "deep_download(['--config', 'gobot/vocab_config.json'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All data and models are saved to root of deeppavlov module + `../download` (`DEEPPAVLOV_ROOT/../download/`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "dstc2_v2_path = deeppavlov.__path__[0] + '/../download/dstc2_v2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data was downloaded to `dstc2_v2_path`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ls /home/vimary/ipavlov/Pilot/deeppavlov/../download/dstc2_v2\n",
      "dstc2-templates.txt  dstc2-tst.jsonlist  resto.sqlite\n",
      "dstc2-trn.jsonlist   dstc2-val.jsonlist\n"
     ]
    }
   ],
   "source": [
    "# The command will only work for linux, do not panic otherwise -- it isn't something crucially important.\n",
    "# You can further just comment bash commands.\n",
    "!echo \"> ls $dstc2_v2_path\"\n",
    "!ls $dstc2_v2_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build our vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.core.commands.train import train_evaluate_model_from_config\n",
    "\n",
    "train_evaluate_model_from_config(\"gobot/vocab_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary was built on data and saved to disk.\n",
    "\n",
    "`save_path = 'vocabs/token.dict'` and component files are saved to `DEEPPAVLOV_ROOT/../download/vocabs/token.dict`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabs_path = deeppavlov.__path__[0] + '/../download/vocabs'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> ls /home/vimary/ipavlov/Pilot/deeppavlov/../download/vocabs\n",
      "token.dict\n"
     ]
    }
   ],
   "source": [
    "!echo \"> ls $vocabs_path\"\n",
    "!ls $vocabs_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the content of the saved \"token.dict\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> head /home/vimary/ipavlov/Pilot/deeppavlov/../download/vocabs/token.dict\n",
      "cheap\t391\n",
      "restaurant\t1179\n",
      "any\t259\n",
      "south\t306\n",
      "address\t781\n",
      "phone\t819\n",
      "number\t825\n",
      "thank\t998\n",
      "you\t1055\n",
      "good\t891\n"
     ]
    }
   ],
   "source": [
    "!echo \"> head $vocabs_path/token.dict\"\n",
    "!head $vocabs_path/token.dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Using trained component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use built vocabulary by initializing it with `build_model_from_config`.\n",
    "\n",
    "We need to add `in` and `out` to component configuration ( to know what are inputs and outputs during prediction ) :\n",
    " - **in** -- a list of data fields that are inputs during inference (prediction)\n",
    " - **out** -- a list of data fields that are outputs during inference (prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_comp_config['in'] = ['utterance']\n",
    "vocab_comp_config['out'] = ['utterance_token_indices']\n",
    "\n",
    "vocab_config['chainer']['pipe'] = [\n",
    "    vocab_comp_config\n",
    "]\n",
    "vocab_config['chainer']['out'] = ['utterance_token_indices']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-29 14:39:57.111 INFO in 'deeppavlov.core.data.vocab'['vocab'] at line 162: [loading vocabulary from /home/vimary/ipavlov/Pilot/download/vocabs/token.dict]\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov.core.commands.infer import build_model_from_config\n",
    "\n",
    "model = build_model_from_config(vocab_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model expects a list of samples (batch) as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[141]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(['hi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model `gobot_dstc2_simple`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a simple goal-oriented bot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.download import deep_download\n",
    "from deeppavlov.core.commands.train import train_evaluate_model_from_config\n",
    "from deeppavlov.core.commands.infer import build_model_from_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"dataset_reader\", \"dataset_iterator\" and \"metadata\" will be the same as for vocabulary only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_config = {}\n",
    "\n",
    "simple_config['dataset_reader'] = dstc2_reader_comp_config\n",
    "simple_config['dataset_iterator'] = dialog_iterator_comp_config\n",
    "simple_config['metadata'] = {}\n",
    "simple_config['metadata']['download'] = [\n",
    "    dstc2_download_config\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "X here is a dict `'x'` containing context 'text', 'intents', db_result', 'prev_resp_act'\n",
    "\n",
    "Y here is a dict `'y'` containing response 'act' and 'text'\n",
    "\n",
    "Prediction `'y_predicted'` here will be only 'text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_config['chainer'] = {}\n",
    "simple_config['chainer']['in'] = ['x']\n",
    "simple_config['chainer']['in_y'] =['y']\n",
    "simple_config['chainer']['out'] = ['y_predicted']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bot consists (`pipe` section) of two components:\n",
    "- **`default_vocab`** (or DefaultVocabulary) component that \n",
    "\n",
    "    - remembers all tokens from user utterances. \n",
    "    - `DefaultVocabulary.__call__` method inputs batch of tokens and outputs their indeces."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vocabulary component will be the same as before, but let's add reference to component using `id` \n",
    "- **id** -- reference name for the component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_comp_config = {\n",
    "    'name': 'default_vocab',\n",
    "    'id': 'token_vocab',\n",
    "    'load_path': 'vocabs/token.dict',\n",
    "    'save_path': 'vocabs/token.dict',\n",
    "    'fit_on': ['x'],\n",
    "    'level': 'token',\n",
    "    'tokenizer': {'name': 'split_tokenizer'}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding vocabulary to chainer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_config['chainer']['pipe'] = []\n",
    "simple_config['chainer']['pipe'].append(vocab_comp_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **`go_bot`** (or GoalOrientedBot) component that\n",
    "    - calls `slot_filler` that for user utterance outputs mentioned slots \n",
    "        (for example, \"i want cheap food\" -> {'pricerange': 'cheap'})\n",
    "    - updates dialog state with `tracker` (DialogStateTracker)\n",
    "        \n",
    "          (for example, if old state was {'location': 'north'}, \n",
    "          and current slots are {'pricerange': 'cheap'}, \n",
    "          then new dialog state will be {'location': 'north', 'pricerange': 'cheap'})\n",
    "    - converts user utterance in string format (`x`) to tokens with `tokenizer`\n",
    "\n",
    "          (for example, \"hi, i want some cheap food\" -> ['hi', ',', 'i', 'want', 'some', 'cheap', 'food'])\n",
    "    - then embeds the tokens with bag-of-words using `bow_embedder`(if not None) and `word_vocab`\n",
    "\n",
    "          (for example, \"cheap\" -> [1, 0, 0, 0, .., 0])\n",
    "    - embeds the utterance with continuous `embedder` (if not None) as a mean of embeddings of utterance tokens\n",
    "        \n",
    "          (for example, \"i\" -> [0.1231, 0.23423, .., 0.03489])\n",
    "    - concatenates embeddings and passes it as an input to a recurrent neural network (RNN)\n",
    "    - trains RNN (with LongShortTermMemory (LSTM) as a core graph) that outputs an action label\n",
    "    - loads templates (mapping from labels to string) using `template_path` and `template_type` and converts action label to string\n",
    "        \n",
    "          (for example, \"bye_msg\" -> \"You are welcome!\")\n",
    "    - fills result string with slot values from dialog state\n",
    "        \n",
    "          (for example, if\n",
    "           dialog state is equal to {'pricerange': 'cheap'}\n",
    "           and output string is \"There are no restaurants in a #pricerange pricerange\"\n",
    "           then the result response will be \"There are no restaurants in a cheap pricerange\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_comp_config = {\n",
    "    'name': 'go_bot',\n",
    "    'in': ['x'],\n",
    "    'in_y': ['y'],\n",
    "    'out': ['y_predicted'],\n",
    "    'word_vocab': None,\n",
    "    'bow_embedder': {\"name\": \"bow\"},\n",
    "    'embedder': None,\n",
    "    'slot_filler': None,\n",
    "    'template_path': 'dstc2_v2/dstc2-templates.txt',\n",
    "    'template_type': 'DualTemplate',\n",
    "    'database': None,\n",
    "    'api_call_action': 'api_call',\n",
    "    'network_parameters': {\n",
    "      'load_path': 'gobot_dstc2_simple/model',\n",
    "      'save_path': 'gobot_dstc2_simple/model',\n",
    "      'dense_size': 64,\n",
    "      'hidden_size': 128,\n",
    "      'learning_rate': 0.002,\n",
    "      'attention_mechanism': None\n",
    "    },\n",
    "    'tokenizer': {'name': 'stream_spacy_tokenizer',\n",
    "                  'lowercase': False},\n",
    "    'tracker': {'name': 'featurized_tracker',\n",
    "                'slot_names': ['pricerange', 'this', 'area', 'food', 'name']},\n",
    "    'main': True,\n",
    "    'debug': False\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how we use vocabulary by reference:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_comp_config['word_vocab'] = '#token_vocab'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Announcing slot filler component.\n",
    "We assume that slot filler is already trained, and use it by referencing it's config."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "slot_filler_comp_config = {\n",
    "    'config_path': deeppavlov.__path__[0] + '/../deeppavlov/configs/ner/slotfill_dstc2.json'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding slot filler to bot component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_comp_config['slot_filler'] = slot_filler_comp_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding `bot_comp_config` to `pipe`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_config['chainer']['pipe'].append(bot_comp_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural network (in the bot) is trained in epochs, and needs data in the form of batches.\n",
    "\n",
    "That is why we are now filling \"train\" section with training parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **train** -- training process configuration\n",
    "     - **train.batch_size** is a number of samples in a batch (feeded to the network during one training step)\n",
    "     - **train.epochs** is a number of iterations over dataset during training\n",
    "     - **train.log_every_n_batches** and **train.log_every_n_epochs** control frequency of logging messages\n",
    "     - **train.metrics** is a list of metrics used to validate our performance\n",
    "     - **train.val_every_n_batches** and **train.val_every_n_epochs** describes how often we calculate metrics on `valid` data split\n",
    "     - **train.validation_patience** is a number of epochs without metric improvement on `valid` data that we are able to endure =)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_bot_train_config = {\n",
    "    'batch_size': 4,\n",
    "    'epochs': 2,\n",
    "    'log_every_n_batches': -1,\n",
    "    'log_every_n_epochs': 1,\n",
    "    'metrics': ['per_item_dialog_accuracy'],\n",
    "    'val_every_n_epochs': 1,\n",
    "    'validation_patience': 20\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_config['train'] = simple_bot_train_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(simple_config, open(\"gobot/simple_config.json\", 'wt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`train.epochs` is set to '2' for now, if you intend to train a smarter model, you should increase it (a range from 10 to 200 epochs is recommended)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deep_download(['--config', slot_filler_comp_config['config_path']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate_model_from_config(\"gobot/simple_config.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's comminicate with the resulting bot. \"exit\" message initiates end of dialogue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_from_config(simple_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-29 14:42:17.99 WARNING in 'deeppavlov.models.go_bot.bot'['bot'] at line 343: No database specified.\n",
      "2018-06-29 14:42:17.99 INFO in 'deeppavlov.models.go_bot.bot'['bot'] at line 344: Made api_call with {'pricerange': 'cheap', 'food': 'italian', 'area': 'north'}, got 0 results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sorry there is no italian restaurant in the north of town.']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(['hi, i want some cheap italian food in the north of town'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-29 14:42:17.110 WARNING in 'deeppavlov.models.go_bot.bot'['bot'] at line 343: No database specified.\n",
      "2018-06-29 14:42:17.110 INFO in 'deeppavlov.models.go_bot.bot'['bot'] at line 344: Made api_call with {'pricerange': 'cheap', 'food': 'italian', 'area': 'north'}, got 0 results.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['Sorry there is no italian restaurant in the north of town.']"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(['thanks, bye'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.reset() # resetting dialog context to start a new one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-28 14:46:37.496 WARNING in 'deeppavlov.models.go_bot.bot'['bot'] at line 343: No database specified.\n",
      "2018-06-28 14:46:37.497 INFO in 'deeppavlov.models.go_bot.bot'['bot'] at line 344: Made api_call with {'pricerange': 'cheap', 'food': 'italian', 'area': 'north'}, got 0 results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Sorry there is no italian restaurant in the north of town.\n",
      ":: i want french food\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-28 14:46:51.212 WARNING in 'deeppavlov.models.go_bot.bot'['bot'] at line 343: No database specified.\n",
      "2018-06-28 14:46:51.212 INFO in 'deeppavlov.models.go_bot.bot'['bot'] at line 344: Made api_call with {'pricerange': 'cheap', 'food': 'french', 'area': 'north'}, got 0 results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Sorry there is no french restaurant in the north of town.\n",
      ":: ok, bye\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-28 14:46:54.950 WARNING in 'deeppavlov.models.go_bot.bot'['bot'] at line 343: No database specified.\n",
      "2018-06-28 14:46:54.950 INFO in 'deeppavlov.models.go_bot.bot'['bot'] at line 344: Made api_call with {'pricerange': 'cheap', 'food': 'french', 'area': 'north'}, got 0 results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Sorry there is no french restaurant in the north of town.\n",
      ":: exit\n"
     ]
    }
   ],
   "source": [
    "# if the cell is running, please do not run other cells in parallel -- there is a possibility of a hangup\n",
    "\n",
    "utterance = \"\"\n",
    "while utterance != 'exit':\n",
    "    print(\">> \" + model([utterance])[0])\n",
    "    utterance = input(':: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model couldn't fill some slots. For example, #address, #phone, #postcode of a restaurant couldn't be inferred from user utterance. \n",
    "\n",
    "A list of available restaurants is required."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model `gobot_dstc2_db`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's now add a database with restaurants and train a new model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing new config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_config = copy.deepcopy(simple_config)\n",
    "\n",
    "db_config['chainer']['pipe'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating database component config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_comp_config = {\n",
    "    'name': 'sqlite_database',\n",
    "    'id': 'restaurant_database', \n",
    "    'save_path': 'dstc2_v2/resto.sqlite',\n",
    "    'primary_keys': ['name'],\n",
    "    'table_name': 'mytable'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding vocab and database components to pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_config['chainer']['pipe'].append(vocab_comp_config)\n",
    "db_config['chainer']['pipe'].append(db_comp_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing bot component config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_with_db_comp_config = copy.deepcopy(bot_comp_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING:** Do no forget to change `load_path` and `save_path` in neural network configuration when \n",
    "             training a new modification. Otherwise previous model's files will be overwritten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_with_db_comp_config['network_parameters']['load_path'] = 'gobot_dstc2_db/model'\n",
    "bot_with_db_comp_config['network_parameters']['save_path'] = 'gobot_dstc2_db/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding database to bot component config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_with_db_comp_config['database'] = '#restaurant_database'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Addind bot component to pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_config['chainer']['pipe'].append(bot_with_db_comp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(db_config, open(\"gobot/db_config.json\", 'wt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new model now updates dialog state not only with entity values mentioned by user (\"i want cheap food\" -> {'pricerange': 'cheap'}), but also with restaurant info taken from sql database of restaurants.\n",
    "\n",
    "Model has a special action `api_call_action`, which initiates a request to sql database with current dialog state and thus receives info of a single matching restaurant.\n",
    "\n",
    "So now such slots as #address, #phone and #postcode can be filled in bot responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate_model_from_config(\"gobot/db_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_from_config(db_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Hello, welcome to the Cambridge restaurant system. You can ask for restaurants by area, price range or food type. How may I help you?\n",
      ":: i want cheap restaurant in the north of town\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-28 14:57:43.780 INFO in 'deeppavlov.models.go_bot.bot'['bot'] at line 344: Made api_call with {'pricerange': 'cheap', 'area': 'north'}, got 2 results.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Da vinci pizzeria is a nice place in the north of town and the prices are cheap.\n",
      ":: ok, give me their phone number\n",
      ">> The phone number of da vinci pizzeria is 01223 351707.\n",
      ":: post code too\n",
      ">> Da vinci pizzeria is a nice place in the north of town and the prices are cheap.\n",
      ":: give me their address\n",
      ">> Da vinci pizzeria is a nice place in the north of town and the prices are cheap.\n",
      ":: bye\n",
      ">> Da vinci pizzeria is a nice place in the north of town and the prices are cheap.\n",
      ":: exit\n"
     ]
    }
   ],
   "source": [
    "# if the cell is running, please do not run other cells in parallel -- there is a possibility of a hangup\n",
    "\n",
    "model.reset() # starting new dialog\n",
    "\n",
    "utterance = \"\"\n",
    "while utterance != 'exit':\n",
    "    print(\">> \" + model([utterance])[0])\n",
    "    utterance = input(':: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model `gobot_dstc2_emb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a goal-oriented bot with fasttext embeddings:\n",
    "\n",
    "**NOTICE:** YOU NEED TO CONSTRUCT A NEW CONFIG YOURSELF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initalizing new config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_config = copy.deepcopy(db_config)\n",
    "\n",
    "emb_config['chainer']['pipe'] = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding vocab and database components to chainer pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_config['chainer']['pipe'].append(vocab_comp_config)\n",
    "emb_config['chainer']['pipe'].append(db_comp_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initalizing embedder component:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_comp_config = {\n",
    "    'id': 'my_embedder',\n",
    "    'name': 'fasttext',\n",
    "    'load_path': 'embeddings/dstc2_fastText_model.bin',\n",
    "    'save_path': 'embeddings/dstc2_fastText_model.bin',\n",
    "    'dim': 100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add embedder component to chainer pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing bot component config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_with_embedder_comp_config = copy.deepcopy(bot_with_db_comp_config)\n",
    "\n",
    "bot_with_embedder_comp_config['network_parameters']['load_path'] = 'gobot_dstc2_emb/model'\n",
    "bot_with_embedder_comp_config['network_parameters']['save_path'] = 'gobot_dstc2_emb/model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add #my_embedder to bot_with_embedder_comp_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add bot_with_embedder_comp_config to chainer pipe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are download urls for new required data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedder_required_data = {\n",
    "    'url': 'http://files.deeppavlov.ai/deeppavlov_data/embeddings/dstc2_fastText_model.bin',\n",
    "    'subdir': 'embeddings'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: add embedder download info to emb_config['metadata']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(emb_config, open(\"gobot/emb_config.json\", 'wt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As far as we are now using embeddings, we added a file named `dstc2_fastText_model.bin` to `metadata.download` section. \n",
    "\n",
    "Let's run data loading again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deep_download(['--config', 'gobot/emb_config.json'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate_model_from_config(\"gobot/emb_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_from_config(emb_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the cell is running, please do not run other cells in parallel -- there is a possibility of a hangup\n",
    "\n",
    "model.reset() # starting new dialog\n",
    "\n",
    "utterance = \"\"\n",
    "while utterance != 'exit':\n",
    "    print(\">> \" + model([utterance])[0])\n",
    "    utterance = input(':: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Appendix _(optional)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Additional materials"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [DataFest Presentation (RU)](https://docs.google.com/presentation/d/1PBPQp-wgQ6aRbm3MsuyGYB_TVg2c7Bf89lhdhbMtC2k)\n",
    "- [CISS Video Lecture](https://youtu.be/uvH1zB7qahI)\n",
    "- [Video Lecture \"Hybrid dialog bot\" (RU)](http://www.youtube.com/watch?v=JJCO7eWCy-M&t=331m19s)\n",
    "- [Video Lecture \"What's inside a dialog system?\" (RU)](http://www.youtube.com/watch?v=JJCO7eWCy-M&t=259m55s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model `gobot_dstc2_full`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's train a very smart goal-oriented bot that uses an attention mechanism over input embeddings \n",
    "\n",
    "(see https://medium.com/syncedreview/a-brief-overview-of-attention-mechanism-13c578ba9129 for more details):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing new config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_config = json.load(open(\"gobot/emb_config.json\", 'rt'))\n",
    "\n",
    "full_config = copy.deepcopy(emb_config)\n",
    "full_config['chainer']['pipe'] = [\n",
    "    vocab_comp_config,\n",
    "    db_comp_config,\n",
    "    embedder_comp_config\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing bot component config:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_with_emb_comp_config = emb_config['chainer']['pipe'][-1]\n",
    "bot_with_attn_comp_config = copy.deepcopy(bot_with_emb_comp_config)\n",
    "\n",
    "bot_with_attn_comp_config['network_parameters']['load_path'] = 'gobot_dstc2_full/model'\n",
    "bot_with_attn_comp_config['network_parameters']['save_path'] = 'gobot_dstc2_full/model'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding attention mechanism to bot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_mechanism_config = {\n",
    "    'action_as_key': True,\n",
    "    'depth': 3,\n",
    "    'hidden_size': 32,\n",
    "    'max_num_tokens': 100,\n",
    "    'projected_align': False,\n",
    "    'type': 'cs_bahdanau'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot_with_attn_comp_config['network_parameters']['attention_mechanism'] = attention_mechanism_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding bot component to pipe:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_config['chainer']['pipe'].append(bot_with_attn_comp_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "json.dump(full_config, open(\"gobot/full_config.json\", 'wt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_evaluate_model_from_config(\"gobot/full_config.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_model_from_config(full_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if the cell is running, please do not run other cells in parallel -- there is a possibility of a hangup\n",
    "\n",
    "model.reset() # starting new dialog\n",
    "\n",
    "utterance = \"\"\n",
    "while utterance != 'exit':\n",
    "    print(\">> \" + model([utterance])[0])\n",
    "    utterance = input(':: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another way of training and infering a component"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build response token vocabulary, but do it without using deeppavlov scripts (without `train_evaluate_model_from_config` and `build_model_from_config`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov.core.data.vocab import DefaultVocabulary\n",
    "from deeppavlov.dataset_readers.dstc2_reader import DSTC2Version2DatasetReader\n",
    "from deeppavlov.dataset_iterators.dialog_iterator import DialogDatasetIterator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing a `DefaultVocabulary` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vocab = DefaultVocabulary(level='token', \n",
    "                            load_path='vocabs/y_token.dict', # path is relative to DEEPPAVLOV_ROOT/../download/ \n",
    "                            save_path='vocabs/y_token.dict',\n",
    "                            tokenizer=lambda s_batch: [s.split() for s in s_batch])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important methods of any trained component are:\n",
    "\n",
    "   - **\\_\\_init\\_\\_(self, *args, *\\*kwargs)**\n",
    "     - intializes a class instance\n",
    "\n",
    "   - **fit(self, data, *args)** or **train_on_batch(self, batch, *args)**\n",
    "     - fits on full data or makes one training step on a batch of data\n",
    "\n",
    "   - **\\_\\_call\\_\\_(self, batch, \\*\\*kwargs)**\n",
    "     - makes prediction (or infers) for each sample in a batch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting batches of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = DSTC2Version2DatasetReader().read(data_path=\"tmp/my_download_of_dstc2\")\n",
    "data_samples = DialogDatasetIterator(data, seed=1443, shuffle=True).get_instances(data_type='all')\n",
    "x_list, y_list = data_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building vocabulary using y batches (`y_list` contains bot responses):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_vocab.fit(y_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Infering from (using) built vocabulary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[43, 3, 26, 5, 0]"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vocab(['is', 'the', 'of', 'restaurant', 'hi'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To call a model `y_vocab(batch)` is the same as to call a \\_\\_call\\_\\_ method `y_vocab.__call__(batch)`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_vocab(['hi']) == y_vocab.__call__(['hi']) == [141]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow_kernel",
   "language": "python",
   "name": "tensorflow_kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
