{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/deeppavlov/DeepPavlov/blob/master/docs/features/models/classification.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Medium](https://img.shields.io/badge/Medium-12100E?style=for-the-badge&logo=medium&logoColor=white)](https://medium.com/deeppavlov/text-classification-using-deeppavlov-library-with-pytorch-and-transformers-f14db5528821)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents \n",
    "\n",
    "1. [Introduction to the task](#1.-Introduction-to-the-task)\n",
    "2. [Get started with the model](#2.-Get-started-with-the-model)\n",
    "3. [Use the model for prediction](#3.-Use-the-model-for-prediction)\n",
    "\n",
    "    3.1. [Predict using Python](#3.1-Predict-using-Python)\n",
    "\n",
    "    3.2. [Predict using CLI](#3.2-Predict-using-CLI)\n",
    "4. [Evaluation](#4.-Evaluation)\n",
    "    \n",
    "    4.1. [from Python](#4.1-Evaluate-from-Python)\n",
    "    \n",
    "    4.2. [from CLI](#4.2-Evaluate-from-CLI)\n",
    "5. [Train the model on your data](#5.-Train-the-model-on-your-data)\n",
    "   \n",
    "    5.1. [from Python](#5.1-Train-your-model-from-Python)\n",
    "   \n",
    "    5.2. [from CLI](#5.2-Train-your-model-from-CLI)\n",
    "6. [Models list](#6.-Models-list)\n",
    "7. [Simple few-shot classifiers](#7.-Simple-few-shot-classifiers)\n",
    "\n",
    "    7.1. [Few-shot setting](#7.1-Few-shot-setting)\n",
    "\n",
    "    7.2. [Multiple languages support](#7.2-Multiple-languages-support)\n",
    "\n",
    "    7.3. [Dataset and Scores](#7.3-Dataset-and-Scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Introduction to the task\n",
    "This section describes a family of BERT-based models that solve a variety of different classification tasks.\n",
    "\n",
    "**Insults detection** is a binary classification task of identying wether a given sequence is an insult of another participant of communication.\n",
    "\n",
    "**Sentiment analysis** is a task of classifying the polarity of the the given sequence. The number of classes may vary depending on the data: positive/negative binary classification, multiclass classification with a neutral class added or with a number of different emotions.\n",
    "\n",
    "The models trained for the **paraphrase detection** task identify whether two sentences expressed with different words convey the same meaning.\n",
    "\n",
    "**Topic classification** refers to the task of classifying an utterance by the topic which belongs to the conversational domain.\n",
    "\n",
    "# 2. Get started with the model\n",
    "\n",
    "First make sure you have the DeepPavlov Library installed.\n",
    "[More info about the first installation.](http://docs.deeppavlov.ai/en/master/intro/installation.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q deeppavlov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then make sure that all the required packages for the model are installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m deeppavlov install insults_kaggle_bert"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`insults_kaggle_bert` is the name of the model's *config_file*. [What is a Config File?](http://docs.deeppavlov.ai/en/master/intro/configuration.html) \n",
    "\n",
    "Configuration file defines the model and describes its hyperparameters. To use another model, change the name of the *config_file* here and further.\n",
    "The full list of NER models with their config names can be found in the [table](#6.-Models-list).\n",
    "\n",
    "There are alternative ways to install the model's packages that do not require executing a separate command -- see the options in the next sections of this page.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# 3. Use the model for prediction\n",
    "\n",
    "## 3.1 Predict using Python\n",
    "\n",
    "After [model installation](#2.-Get-started-with-the-model) build it from the config and use it for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import build_model\n",
    "\n",
    "model = build_model('insults_kaggle_bert', download=True, install=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `download` argument defines whether it is necessary to download the files defined in the `download` section of the config: usually it provides the links to the train and test data, to the pretrained models, or to the embeddings.\n",
    "\n",
    "Setting the `install` argument to `True` is equivalent to executing the command line `install` command. If set to `True`, it will first install all the required packages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Input format**: List[sentences]\n",
    "\n",
    "**Output format**: List[labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Insult', 'Not Insult']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(['You are kind of stupid', 'You are a wonderful person!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Predict using CLI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also get predictions in an interactive mode through CLI (Command Line Interface)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python deeppavlov interact insults_kaggle_bert -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`-d` is an optional download key (alternative to `download=True` in Python code). The key `-d` is used to download the pre-trained model along with embeddings and all other files needed to run the model.\n",
    "\n",
    "Or make predictions for samples from *stdin*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python deeppavlov predict insults_kaggle_bert -f <file-name>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Evaluation\n",
    "\n",
    "## 4.1 Evaluate from Python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from deeppavlov import evaluate_model\n",
    "\n",
    "model = evaluate_model('insults_kaggle_bert', download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 Evaluate from CLI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m deeppavlov evaluate insults_kaggle_bert -d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Train the model on your data\n",
    "\n",
    "## 5.1 Train your model from Python\n",
    "\n",
    "### Provide your data path\n",
    "\n",
    "To train the model on your data, you need to change the path to the training data in the *config_file*.\n",
    "\n",
    "Parse the *config_file* and change the path to your data from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "~/.deeppavlov/downloads/insults_data\n"
     ]
    }
   ],
   "source": [
    "from deeppavlov import train_model\n",
    "from deeppavlov.core.commands.utils import parse_config\n",
    "\n",
    "model_config = parse_config('insults_kaggle_bert')\n",
    "\n",
    "# dataset that the model was trained on\n",
    "print(model_config['dataset_reader']['data_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Provide a *data_path* to your own dataset. You can also change any of the hyperparameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download and unzip a new example dataset\n",
    "!wget http://files.deeppavlov.ai/datasets/insults_data.tar.gz\n",
    "!tar -xzvf \"insults_data.tar.gz\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# provide a path to the directory with your train, valid and test files\n",
    "model_config['dataset_reader']['data_path'] = \"./contents/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Train dataset format\n",
    "\n",
    "### Train the model using new config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train_model(model_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use your model for prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Insult', 'Not Insult']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(['You are kind of stupid', 'You are a wonderful person!'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2 Train your model from CLI\n",
    "\n",
    "To train the model on your data, create a copy of a config file and change the *data_path* variable in it. After that, train the model using your new *config_file*. You can also change any of the hyperparameters of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m deeppavlov train model_config.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Models list\n",
    "\n",
    "The table presents a list of all of the classification models available in DeepPavlov Library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Config name  | Language | Task | Dataset | Model Size | Metric | Score |\n",
    "| :--- | --- | --- | --- | --- | --- | ---: |\n",
    "| insults_kaggle_bert | En | Insults | [Insults](https://www.kaggle.com/c/detecting-insults-in-social-commentary) | 1.1 GB | ROC-AUC | 0.8770 |\n",
    "| paraphraser_rubert | Ru | Paraphrase | [Paraphrase Corpus](http://paraphraser.ru/download/) | 2.0 GB | F1 | 0.8738 |\n",
    "| paraphraser_convers_distilrubert_2L | Ru | Paraphrase | [Paraphrase Corpus](http://paraphraser.ru/download/) | 1.2 GB | F1 | 0.7396 |\n",
    "| paraphraser_convers_distilrubert_6L | Ru | Paraphrase | [Paraphrase Corpus](http://paraphraser.ru/download/) | 1.6 GB | F1 | 0.8354 |\n",
    "| sentiment_sst_conv_bert | En | Sentiment | [SST](https://paperswithcode.com/dataset/sst) | 1.1 GB | Accuracy | 0.6626 |\n",
    "| sentiment_twitter | Ru | Sentiment | [Twitter Mokoron](http://study.mokoron.com/) | 6.2 GB | F1-macro | 0.9961 |\n",
    "| rusentiment_bert | Ru | Sentiment | [RuSentiment](https://text-machine.cs.uml.edu/projects/rusentiment/) | 1.3 GB | F1-weighted | 0.7005 |\n",
    "| rusentiment_convers_bert | Ru | Sentiment | [RuSentiment](https://text-machine.cs.uml.edu/projects/rusentiment/) | 1.5 GB | F1-weighted | 0.7724  |\n",
    "| topics_distilbert_base_uncased | En | Topics | [DeepPavlov Topics](https://deeppavlov.ai/datasets/topics) | 6.2 GB | F1-macro | 0.9961 |\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Simple few-shot classifiers\n",
    "\n",
    "Additionally, in the [faq](https://github.com/deeppavlov/DeepPavlov/tree/master/deeppavlov/configs/faq) section you can find a config for a fast and simple pre-BERT model, which consists of a fasttext vectorizer and a simple logistic regression classifier. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1 Few-shot setting\n",
    "\n",
    "In the current setting the config can be used for few-shot classification -- a task, in which only a few training examples are available for each class (usually 5 or 10). Note that the configs take the full version of the dataset as the input and sample N examples for each class of the train data in the iterator. \n",
    "\n",
    "The sampling is done in the `few_shot_iterator` component of the pipeline and the `shot` format defines the number of examples to be sampled. \n",
    "In order to use the config for normal classification you can change the `dataset_iterator` to the `basic_classification_iterator` or set the `shot` parameter to `None`."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2 Multiple languages support\n",
    "\n",
    "Currently this config are designed to support classificcation in two languages: English and Russian. \n",
    "\n",
    "In order to work with the language you need, define the `LANGUAGE` variable in the `metadata` section (`ru` or `en`) of the config and change the Spacy model (if used) to the corresponding one: `SPACY_MODEL` variable to `en_core_web_sm` for English or `ru_core_news_sm` for Russian.\n",
    "\n",
    "You can do that by directly editing the condfig file through a text editor or change it through Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "en\n"
     ]
    }
   ],
   "source": [
    "model_config = parse_config('fasttext_logreg')\n",
    "\n",
    "print(model_config['metadata']['variables']['LANGUAGE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config['metadata']['variables']['LANGUAGE'] = 'ru'\n",
    "model_config['metadata']['variables']['SPACY_MODEL'] = 'ru_core_news_sm'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3 Dataset and Scores\n",
    "\n",
    "To demonstrate the performance of the model in two languages, we use the English and Russian subsets of [the MASSIVE dataset](https://github.com/alexa/massive). \n",
    "\n",
    "MASSIVE is a parallel dataset of utterrances in 52 languages with annotations for the Natural Language Understanding tasks of intent prediction and slot annotation. We only employ the intent classification data. You can see the results of the given configs in 5-shot classification setting in the table below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Config name | Language | Train accuracy | Validation accuracy | Test accuracy |\n",
    "| :--- | --- | --- | --- | ---: |\n",
    "| fasttext_logreg | en | 0.9632 | 0.5239 | 0.5155 |\n",
    "| fasttext_logreg | ru | 0.9632 | 0.4565 | 0.4304 |"
   ]
  }
],
"metadata": {
 "accelerator": "GPU"
},
"nbformat": 4,
"nbformat_minor": 4
}